{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "weapon_new.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnKM6c6Z7q5C4mgmxWdish",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannan178/Colab_Implementations/blob/master/weapon_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jPzycqgiT01",
        "colab_type": "code",
        "outputId": "4e1b0cb1-e0ba-432a-9cac-8271ffed1234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!git clone https://github.com/KyleMoore1/weapon-detect.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'weapon-detect'...\n",
            "remote: Enumerating objects: 446, done.\u001b[K\n",
            "remote: Total 446 (delta 0), reused 0 (delta 0), pack-reused 446\u001b[K\n",
            "Receiving objects: 100% (446/446), 2.38 MiB | 2.14 MiB/s, done.\n",
            "Resolving deltas: 100% (268/268), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtFxas2UitCN",
        "colab_type": "code",
        "outputId": "4849e2d0-2f02-4588-8108-c28c6a248e95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd /content/weapon-detect"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/weapon-detect\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8EEUcA0jzzZ",
        "colab_type": "code",
        "outputId": "82653e7c-bb6f-421c-89a9-f4f0670ec3ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget https://pjreddie.com/media/files/yolov3.weights "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-12 05:19:20--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   234KB/s    in 13m 31s \n",
            "\n",
            "2020-03-12 05:32:53 (298 KB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aj1B5tiTnub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 \n",
        "from util import *\n",
        "import argparse\n",
        "import os \n",
        "import os.path as osp\n",
        "from darknet import Darknet\n",
        "from preprocess import prep_image, inp_to_image\n",
        "import pandas as pd\n",
        "import random \n",
        "import pickle as pkl\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJjAdbERTs8K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class test_net(nn.Module):\n",
        "    def __init__(self, num_layers, input_size):\n",
        "        super(test_net, self).__init__()\n",
        "        self.num_layers= num_layers\n",
        "        self.linear_1 = nn.Linear(input_size, 5)\n",
        "        self.middle = nn.ModuleList([nn.Linear(5,5) for x in range(num_layers)])\n",
        "        self.output = nn.Linear(5,2)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.view(-1)\n",
        "        fwd = nn.Sequential(self.linear_1, *self.middle, self.output)\n",
        "        return fwd(x)\n",
        "        \n",
        "def get_test_input(input_dim, CUDA):\n",
        "    img = cv2.imread(\"dog-cycle-car.png\")\n",
        "    img = cv2.resize(img, (input_dim, input_dim)) \n",
        "    img_ =  img[:,:,::-1].transpose((2,0,1))\n",
        "    img_ = img_[np.newaxis,:,:,:]/255.0\n",
        "    img_ = torch.from_numpy(img_).float()\n",
        "    img_ = Variable(img_)\n",
        "    \n",
        "    if CUDA:\n",
        "        img_ = img_.cuda()\n",
        "    num_classes\n",
        "    return img_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvk4pkoKTv-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def arg_parse():\n",
        "    \"\"\"\n",
        "    Parse arguements to the detect module\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    parser = argparse.ArgumentParser(description='YOLO v3 Detection Module')\n",
        "   \n",
        "    parser.add_argument(\"--images\", dest = 'images', help = \n",
        "                        \"Image / Directory containing images to perform detection upon\", default= '/content/weapon-detect/imgs', type = str)\n",
        "    parser.add_argument(\"--det\", dest = 'det', help = \n",
        "                        \"Image / Directory to store detections to\",\n",
        "                        default = \"/content/weapon-detect/det\", type = str)\n",
        "    parser.add_argument(\"--bs\", dest = \"bs\", help = \"Batch size\", default = 2)\n",
        "    parser.add_argument(\"--confidence\", dest = \"confidence\", help = \"Object Confidence to filter predictions\", default = 0.5)\n",
        "    parser.add_argument(\"--nms_thresh\", dest = \"nms_thresh\", help = \"NMS Threshhold\", default = 0.4)\n",
        "    parser.add_argument(\"--cfg\", dest = 'cfgfile', help = \n",
        "                        \"Config file\",\n",
        "                        default = \"cfg/yolov3.cfg\", type = str)\n",
        "    parser.add_argument(\"--weights\", dest = 'weightsfile', help = \n",
        "                        \"weightsfile\",\n",
        "                        default = \"yolov3.weights\", type = str)\n",
        "    parser.add_argument(\"--reso\", dest = 'reso', help = \n",
        "                        \"Input resolution of the network. Increase to increase accuracy. Decrease to increase speed\",\n",
        "                        default = \"416\", type = str)\n",
        "    parser.add_argument(\"--scales\", dest = \"scales\", help = \"Scales to use for detection\",\n",
        "                        default = \"1,2,3\", type = str)\n",
        "    \n",
        "    return parser.parse_args(args=[])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csk90L6TT0Zc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 806
        },
        "outputId": "a0e06f0e-35dd-4c2c-f93e-10d827684732"
      },
      "source": [
        "if __name__ ==  '__main__':\n",
        "    args = arg_parse()\n",
        "    \n",
        "    scales = args.scales\n",
        "\n",
        "    images = args.images\n",
        "    batch_size = int(args.bs)\n",
        "    confidence = float(args.confidence)\n",
        "    nms_thesh = float(args.nms_thresh)\n",
        "    start = 0\n",
        "\n",
        "    CUDA = torch.cuda.is_available()\n",
        "\n",
        "    num_classes = 80\n",
        "    classes = load_classes('data/coco.names') \n",
        "\n",
        "    #Set up the neural network\n",
        "    print(\"Loading network.....\")\n",
        "    model = Darknet(args.cfgfile)\n",
        "    model.load_weights(args.weightsfile)\n",
        "    print(\"Network successfully loaded\")\n",
        "    \n",
        "    model.net_info[\"height\"] = args.reso\n",
        "    inp_dim = int(model.net_info[\"height\"])\n",
        "    assert inp_dim % 32 == 0 \n",
        "    assert inp_dim > 32\n",
        "\n",
        "    #If there's a GPU availible, put the model on GPU\n",
        "    if CUDA:\n",
        "        model.cuda()\n",
        "    \n",
        "    \n",
        "    #Set the model in evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    read_dir = time.time()\n",
        "    #Detection phase\n",
        "    try:\n",
        "        imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images) if os.path.splitext(img)[1] == '.png' or os.path.splitext(img)[1] =='.jpeg' or os.path.splitext(img)[1] =='.jpg']\n",
        "    except NotADirectoryError:\n",
        "        imlist = []\n",
        "        imlist.append(osp.join(osp.realpath('.'), images))\n",
        "    except FileNotFoundError:\n",
        "        print (\"No file or directory with the name {}\".format(images))\n",
        "        exit()\n",
        "        \n",
        "    if not os.path.exists(args.det):\n",
        "        os.makedirs(args.det)\n",
        "        \n",
        "    load_batch = time.time()\n",
        "    \n",
        "    batches = list(map(prep_image, imlist, [inp_dim for x in range(len(imlist))]))\n",
        "    im_batches = [x[0] for x in batches]\n",
        "    orig_ims = [x[1] for x in batches]\n",
        "    im_dim_list = [x[2] for x in batches]\n",
        "    im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "    \n",
        "    \n",
        "    \n",
        "    if CUDA:\n",
        "        im_dim_list = im_dim_list.cuda()\n",
        "    \n",
        "    leftover = 0\n",
        "    \n",
        "    if (len(im_dim_list) % batch_size):\n",
        "        leftover = 1\n",
        "        \n",
        "        \n",
        "    if batch_size != 1:\n",
        "        num_batches = len(imlist) // batch_size + leftover            \n",
        "        im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                            len(im_batches))]))  for i in range(num_batches)]        \n",
        "\n",
        "\n",
        "    i = 0\n",
        "    \n",
        "\n",
        "    write = False\n",
        "    model(get_test_input(inp_dim, CUDA), CUDA)\n",
        "    \n",
        "    start_det_loop = time.time()\n",
        "    \n",
        "    objs = {}\n",
        "    \n",
        "    \n",
        "    \n",
        "    for batch in im_batches:\n",
        "        #load the image \n",
        "        start = time.time()\n",
        "        if CUDA:\n",
        "            batch = batch.cuda()\n",
        "        \n",
        "\n",
        "        #Apply offsets to the result predictions\n",
        "        #Tranform the predictions as described in the YOLO paper\n",
        "        #flatten the prediction vector \n",
        "        # B x (bbox cord x no. of anchors) x grid_w x grid_h --> B x bbox x (all the boxes) \n",
        "        # Put every proposed box as a row.\n",
        "        with torch.no_grad():\n",
        "            prediction = model(Variable(batch), CUDA)\n",
        "        \n",
        "#        prediction = prediction[:,scale_indices]\n",
        "\n",
        "        \n",
        "        #get the boxes with object confidence > threshold\n",
        "        #Convert the cordinates to absolute coordinates\n",
        "        #perform NMS on these boxes, and save the results \n",
        "        #I could have done NMS and saving seperately to have a better abstraction\n",
        "        #But both these operations require looping, hence \n",
        "        #clubbing these ops in one loop instead of two. \n",
        "        #loops are slower than vectorised operations. \n",
        "        \n",
        "        prediction = write_results(prediction, confidence, num_classes, nms = True, nms_conf = nms_thesh)\n",
        "        \n",
        "        \n",
        "        if type(prediction) == int:\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        end = time.time()\n",
        "        \n",
        "                    \n",
        "#        print(end - start)\n",
        "\n",
        "            \n",
        "\n",
        "        prediction[:,0] += i*batch_size\n",
        "        \n",
        "    \n",
        "            \n",
        "          \n",
        "        if not write:\n",
        "            output = prediction\n",
        "            write = 1\n",
        "        else:\n",
        "            output = torch.cat((output,prediction))\n",
        "            \n",
        "        \n",
        "        \n",
        "\n",
        "        for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "            im_id = i*batch_size + im_num\n",
        "            objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "            print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "            print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "            print(\"----------------------------------------------------------\")\n",
        "        i += 1\n",
        "\n",
        "        \n",
        "        if CUDA:\n",
        "            torch.cuda.synchronize()\n",
        "    \n",
        "    try:\n",
        "        output\n",
        "    except NameError:\n",
        "        print(\"No detections were made\")\n",
        "        exit()\n",
        "        \n",
        "    im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
        "    \n",
        "    scaling_factor = torch.min(inp_dim/im_dim_list,1)[0].view(-1,1)\n",
        "    \n",
        "    \n",
        "    output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
        "    output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
        "    \n",
        "    \n",
        "    \n",
        "    output[:,1:5] /= scaling_factor\n",
        "    \n",
        "    for i in range(output.shape[0]):\n",
        "        output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
        "        output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
        "        \n",
        "        \n",
        "    output_recast = time.time()\n",
        "    \n",
        "    \n",
        "    class_load = time.time()\n",
        "\n",
        "    colors = pkl.load(open(\"pallete\", \"rb\"))\n",
        "    \n",
        "    \n",
        "    draw = time.time()\n",
        "\n",
        "\n",
        "    def write(x, batches, results):\n",
        "        c1 = tuple(x[1:3].int())\n",
        "        c2 = tuple(x[3:5].int())\n",
        "        img = results[int(x[0])]\n",
        "        cls = int(x[-1])\n",
        "        label = \"{0}\".format(classes[cls])\n",
        "        color = random.choice(colors)\n",
        "        cv2.rectangle(img, c1, c2,color, 1)\n",
        "        t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "        c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "        cv2.rectangle(img, c1, c2,color, -1)\n",
        "        cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1)\n",
        "        return img\n",
        "    \n",
        "            \n",
        "    list(map(lambda x: write(x, im_batches, orig_ims), output))\n",
        "      \n",
        "    det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(args.det,x.split(\"/\")[-1]))\n",
        "    \n",
        "    list(map(cv2.imwrite, det_names, orig_ims))\n",
        "    \n",
        "    end = time.time()\n",
        "    \n",
        "    print()\n",
        "    print(\"SUMMARY\")\n",
        "    print(\"----------------------------------------------------------\")\n",
        "    print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "    print()\n",
        "    print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "    print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "    print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
        "    print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "    print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "    print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
        "    print(\"----------------------------------------------------------\")\n",
        "\n",
        "    \n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network.....\n",
            "Network successfully loaded\n",
            "giraffe.jpg          predicted in  1.456 seconds\n",
            "Objects Detected:    zebra giraffe giraffe\n",
            "----------------------------------------------------------\n",
            "messi.jpg            predicted in  1.456 seconds\n",
            "Objects Detected:    person person person sports ball\n",
            "----------------------------------------------------------\n",
            "herd_of_horses.jpg   predicted in  1.315 seconds\n",
            "Objects Detected:    horse horse horse horse\n",
            "----------------------------------------------------------\n",
            "person.jpg           predicted in  1.315 seconds\n",
            "Objects Detected:    person dog horse\n",
            "----------------------------------------------------------\n",
            "eagle.jpg            predicted in  1.305 seconds\n",
            "Objects Detected:    bird\n",
            "----------------------------------------------------------\n",
            "img4.jpg             predicted in  1.305 seconds\n",
            "Objects Detected:    chair chair chair clock\n",
            "----------------------------------------------------------\n",
            "img2.jpg             predicted in  1.327 seconds\n",
            "Objects Detected:    train\n",
            "----------------------------------------------------------\n",
            "img3.jpg             predicted in  1.327 seconds\n",
            "Objects Detected:    car car car car car car car truck traffic light\n",
            "----------------------------------------------------------\n",
            "scream.jpg           predicted in  1.320 seconds\n",
            "Objects Detected:    \n",
            "----------------------------------------------------------\n",
            "img1.jpg             predicted in  1.320 seconds\n",
            "Objects Detected:    person dog\n",
            "----------------------------------------------------------\n",
            "dog.jpg              predicted in  0.677 seconds\n",
            "Objects Detected:    bicycle truck dog\n",
            "----------------------------------------------------------\n",
            "\n",
            "SUMMARY\n",
            "----------------------------------------------------------\n",
            "Task                     : Time Taken (in seconds)\n",
            "\n",
            "Reading addresses        : 0.000\n",
            "Loading batch            : 1.653\n",
            "Detection (11 images)    : 14.817\n",
            "Output Processing        : 0.000\n",
            "Drawing Boxes            : 0.107\n",
            "Average time_per_img     : 1.507\n",
            "----------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}